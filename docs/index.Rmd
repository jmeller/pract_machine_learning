---
title: "Predicting the Quality of Execution of Weightlifting Exercises"
author: "Jan"
subtitle: Practical Machine Learning Course Project
output: github_document
---


# Executive Summary
- I analyzed a data set containing the weightlifting movements of six candidates who were tracked with four different gyrosensors.
- After a first exploratory analysis, I performed a data imputation to fill up missing values in the feature data
- Two powerful classification models were chosen, namely extreme gradient boosting and a random forest
- Both models performed extremely well on the training data set with 99.9\% (random forest) and 99.2\% (xgb) out-of-sample performance measured by a five-fold cross-validation approach

```{r data_loading, include=FALSE, results='hide'}
lapply(c("tidyverse", "caret", "visdat"), 
       function(lib) 
         suppressWarnings(suppressMessages(require(lib, character.only = T))))
# parameters
file.path <- "../data/"
# data import
training <- read_csv(paste0(file.path, "pml-training.csv"))
testing <- read_csv(paste0(file.path, "pml-testing.csv"))
```

# Exploratory analyses

After loading the provided data set, I performed a first exploratory analysis. There exist five different classes according to which the movements were performed: A (exactly according to the specification), B (throwing the ellbows to the front), C (lifting the dumbbell only halfway), D (lowering the dumbbell only halfway) and E (throwing the hips to the front). As can be seen, classes are distributed almost equally over the training set. 
```{r exp_raw_data1, echo=FALSE, out.width='.45\\linewidth'}
table(training$classe)
```

Moreover, I noted a considerable amount of missing values as shown in the graph below.
```{r exp_raw_data2, echo=FALSE}
## calculate fill rates
na_perc <- function(col){sum(is.na(col))/nrow(col)}
fill.col <- 1 - sapply(1:ncol(training), function(col_idx){
  training[, col_idx] %>% na_perc
  })

training[sample(1:nrow(training), 100),] %>% vis_dat(sort_type = T) # we see that a lot of the feature data is missing
```

# Data Preprocessing

Considering the amount of missingness in the feature data, I first performed a data cleaning step. I excluded feature columns with less than 50\% fill rate. Moreover, for the rest of the columns with missing values, I imputed the latter by the mean and added an indicator column. The following graph shows the distribution of different data types in my training sample. 

```{r data_preprocessing}
# need factors for classification problem
training <- training %>% 
  mutate(classe = factor(classe, 
                         levels = c("A", "B", "C", "D", "E"))) 

# exclude cols w. < 50% fill rate
exclude.cols <- which(fill.col < 1)
na.cols <- which(fill.col >= .5 & fill.col < 1)
training_preproc <- training %>% select(-exclude.cols)

# impute missing values and create missing value indicators (mvi)
training_imputed <- training %>% select(c(1, na.cols)) %>% 
  mutate(magnet_dumbbell_z_imp = ifelse(is.na(magnet_dumbbell_z), 
                                        mean(magnet_dumbbell_z, na.rm = T), 
                                        magnet_dumbbell_z),
         magnet_forearm_y_imp = ifelse(is.na(magnet_forearm_y), 
                                       mean(magnet_forearm_y, na.rm = T), 
                                       magnet_forearm_y),
         magnet_forearm_z_imp = ifelse(is.na(magnet_forearm_z), 
                                       mean(magnet_forearm_z, na.rm = T), 
                                       magnet_forearm_z),
         magnet_dumbbell_z_mvi = ifelse(is.na(magnet_dumbbell_z), 1, 0),
         magnet_forearm_y_mvi = ifelse(is.na(magnet_forearm_y),  1, 0),
         magnet_forearm_z_mvi = ifelse(is.na(magnet_forearm_z),  1, 0)) %>%
  select(-c(magnet_dumbbell_z, magnet_forearm_y, magnet_forearm_z))

# create training data set
training_preproc <- merge(training_preproc, training_imputed, by = "X1") %>% select(-"X1")
training_preproc[sample(1:nrow(training_preproc), 100),] %>% vis_dat(sort_type = T)
```


# Predictive modeling

In the following step, I chose to first train a gradient boosting model to predict the specific class of movement execution based on the available feature data. I used the caret package and selected a five-fold cross-validation approach to choose the best model configuration based on accuracy.

```{r pred_model_xgb}
# create the caret experiment using the trainControl() function
ctrl <- trainControl(
  method = "cv", number = 5, # 5-fold CV
  selectionFunction = "best", # select the best performer
  savePredictions = TRUE
)

# xgb
if(file.exists("../models/model_xgb.rds")){
  model.xgb <- readRDS("../models/model_xgb.rds")
} else {
  xgb.grid <- expand.grid(nrounds = c(50, 100, 150), 
                          max_depth = c(6, 7, 8), eta = 0.3, 
                          subsample = 1, colsample_bytree = 1, 
                          gamma = 0, min_child_weight = 1)
  
  model.xgb <- train(classe ~ ., 
                     method = "xgbTree", 
                     data = training_preproc,
                     trControl = ctrl,
                     tuneGrid = xgb.grid)
  model.xgb
  saveRDS(model.xgb, file = "../models/model_xgb.rds")
}
```

Similarly, I trained a random forest model and also chose the best model configuration based on the accuracy measure over a five-fold cross-validation.

```{r pred_model_ranger}
if(file.exists("../models/model_ranger.rds")){
  model.ranger <- readRDS("../models/model_ranger.rds")
} else {
  ranger.grid <- expand.grid(mtry = 5:20, splitrule = "gini", 
                             min.node.size = c(1, 3, 5))
  model.ranger <- train(classe ~ .,
                        method = "ranger",
                        data = training_preproc,
                        trControl = ctrl, 
                        tuneGrid = ranger.grid)
  model.ranger
  saveRDS(model.ranger, file = "../models/model_ranger.rds")
}
```

# Evaluation

In the following, I compare the out-of-sample results of the two model classes calculated from the cross-validation of the training data set. As can be seen, both models perform extremely well. Due to its slightly better performance, I chose the random forest model as the final model and used it to predict the instances of the test sample.

```{r model_eval}
model.xgb
model.ranger
```
# Prediction of new instances

In order to predict the instances of the test sample, I first preprocessed the test sample in the same way as the training sample. Of particular importance was that I only used information from the training sample when imputing the missing values in the test data set. For this reason, I filled the missing values with the mean values from the training sample of the respective columns. 

```{r model_pred}
testing_preproc <- testing %>% select(-exclude.cols)
# impute missing values and create missing value indicators (mvi)
testing_imputed <- testing %>% select(c(1, na.cols)) %>% 
  mutate(magnet_dumbbell_z_imp = ifelse(is.na(magnet_dumbbell_z), 
                                        mean(training$magnet_dumbbell_z, na.rm = T), 
                                        magnet_dumbbell_z),
         magnet_forearm_y_imp = ifelse(is.na(magnet_forearm_y), 
                                       mean(training$magnet_forearm_y, na.rm = T), 
                                       magnet_forearm_y),
         magnet_forearm_z_imp = ifelse(is.na(magnet_forearm_z), 
                                       mean(training$magnet_forearm_z, na.rm = T), 
                                       magnet_forearm_z),
         magnet_dumbbell_z_mvi = ifelse(is.na(magnet_dumbbell_z), 1, 0),
         magnet_forearm_y_mvi = ifelse(is.na(magnet_forearm_y),  1, 0),
         magnet_forearm_z_mvi = ifelse(is.na(magnet_forearm_z),  1, 0)) %>%
  select(-c(magnet_dumbbell_z, magnet_forearm_y, magnet_forearm_z))

testing_preproc <- merge(testing_preproc, testing_imputed, by = "X1") %>% select(-"X1")
predictions <- predict(model.ranger, newdata = testing_preproc)
data.frame(testing$X1, predictions)
```

# Conclusion

The outcome of the machine learning project suggests that the quality of weightlifting movements can be predicted based on gyrosensor measurements with a very high accuracy. Out of two very well performing classification models, the random forest was slightly superior and achieved a 99.9\% out-of-sample accuracy measured with five-fold cross-validation.

